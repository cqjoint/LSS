{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee615db-0dd8-4e3a-a74f-10e9903b14fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, MaxPooling1D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_excel('hechuan ube.xlsx')\n",
    "\n",
    "# Split the data into features (X) and target variable (Y)\n",
    "X = data.drop(['ID', 'los', 'elos'], axis=1)\n",
    "Y = data['elos']\n",
    "\n",
    "# Convert Y to binary classification (if necessary)\n",
    "Y = (Y > Y.median()).astype(int)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.4, random_state=42)\n",
    "\n",
    "# 数据增强（SMOTE）\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, Y_train_res = smote.fit_resample(X_train, Y_train)\n",
    "\n",
    "# 特征标准化\n",
    "scaler = StandardScaler()\n",
    "X_train_res = scaler.fit_transform(X_train_res)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Function to plot ROC curve\n",
    "def plot_roc_curve(fpr, tpr, roc_auc, label):\n",
    "    plt.plot(fpr, tpr, label=f'{label} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "# Initialize a plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Performance metrics storage\n",
    "metrics = {}\n",
    "\n",
    "# Function to calculate and store metrics\n",
    "def calculate_metrics(y_true, y_pred, label):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    metrics[label] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    }\n",
    "\n",
    "# 1. XGBoost (abbreviation: XGB)\n",
    "xgb_model = XGBClassifier(\n",
    "    random_state=42,\n",
    "    n_estimators=180,\n",
    "    max_depth=2,  # 降低树的深度以减少过拟化\n",
    "    reg_alpha=8,  # 增加正则化\n",
    "    reg_lambda=8,  # 增加正则化\n",
    "    min_child_weight=3,  # 增加最小子节点权重以减少过拟化\n",
    "    gamma=1.0,  # 增加 gamma 以减少过拟化\n",
    "    subsample=0.8,  # 减少采样率以增加随机性\n",
    "    colsample_bytree=0.8  # 减少特征采样率以增加随机性\n",
    ")\n",
    "xgb_model.fit(X_train_res, Y_train_res)\n",
    "Y_pred_proba_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
    "# 调整分类阈值\n",
    "Y_pred_xgb = (Y_pred_proba_xgb > 0.8).astype(int)\n",
    "calculate_metrics(Y_test, Y_pred_xgb, 'XGB')\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(Y_test, Y_pred_proba_xgb)\n",
    "roc_auc_xgb = auc(fpr_xgb, tpr_xgb)\n",
    "plot_roc_curve(fpr_xgb, tpr_xgb, roc_auc_xgb, 'XGB')\n",
    "\n",
    "# 2. Gradient Boosting Machine (abbreviation: GBM)\n",
    "gbm_model = GradientBoostingClassifier(random_state=42, learning_rate=0.1)\n",
    "gbm_model.fit(X_train_res, Y_train_res)\n",
    "Y_pred_proba_gbm = gbm_model.predict_proba(X_test)[:, 1]\n",
    "Y_pred_gbm = (Y_pred_proba_gbm > 0.8).astype(int)\n",
    "calculate_metrics(Y_test, Y_pred_gbm, 'GBM')\n",
    "fpr_gbm, tpr_gbm, _ = roc_curve(Y_test, Y_pred_proba_gbm)\n",
    "roc_auc_gbm = auc(fpr_gbm, tpr_gbm)\n",
    "plot_roc_curve(fpr_gbm, tpr_gbm, roc_auc_gbm, 'GBM')\n",
    "\n",
    "# 3. Random Forest (abbreviation: RF)\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=50, max_depth=5, min_samples_split=10)\n",
    "rf_model.fit(X_train_res, Y_train_res)\n",
    "Y_pred_proba_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "Y_pred_rf = (Y_pred_proba_rf > 0.8).astype(int)\n",
    "calculate_metrics(Y_test, Y_pred_rf, 'RF')\n",
    "fpr_rf, tpr_rf, _ = roc_curve(Y_test, Y_pred_proba_rf)\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "plot_roc_curve(fpr_rf, tpr_rf, roc_auc_rf, 'RF')\n",
    "\n",
    "# 4. Logistic Regression (abbreviation: LR)\n",
    "lr_model = LogisticRegression(random_state=42, penalty='l2', C=0.1)\n",
    "lr_model.fit(X_train_res, Y_train_res)\n",
    "Y_pred_proba_lr = lr_model.predict_proba(X_test)[:, 1]\n",
    "Y_pred_lr = (Y_pred_proba_lr > 0.5).astype(int)\n",
    "calculate_metrics(Y_test, Y_pred_lr, 'LR')\n",
    "fpr_lr, tpr_lr, _ = roc_curve(Y_test, Y_pred_proba_lr)\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "plot_roc_curve(fpr_lr, tpr_lr, roc_auc_lr, 'LR')\n",
    "\n",
    "# 5. Lasso Logistic Regression (abbreviation: Lasso LR)\n",
    "lasso_lr_model = LogisticRegression(penalty='l1', solver='liblinear', C=0.1, random_state=42)\n",
    "lasso_lr_model.fit(X_train_res, Y_train_res)\n",
    "Y_pred_proba_lasso_lr = lasso_lr_model.predict_proba(X_test)[:, 1]\n",
    "Y_pred_lasso_lr = (Y_pred_proba_lasso_lr > 0.5).astype(int)\n",
    "calculate_metrics(Y_test, Y_pred_lasso_lr, 'Lasso LR')\n",
    "fpr_lasso_lr, tpr_lasso_lr, _ = roc_curve(Y_test, Y_pred_proba_lasso_lr)\n",
    "roc_auc_lasso_lr = auc(fpr_lasso_lr, tpr_lasso_lr)\n",
    "plot_roc_curve(fpr_lasso_lr, tpr_lasso_lr, roc_auc_lasso_lr, 'Lasso LR')\n",
    "\n",
    "# 6. Convolutional Neural Network (abbreviation: CNN)\n",
    "# Reshape data for CNN (assuming 1D convolution)\n",
    "X_train_cnn = X_train_res.reshape((X_train_res.shape[0], X_train_res.shape[1], 1))\n",
    "X_test_cnn = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train_res.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "cnn_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "cnn_model.fit(X_train_cnn, Y_train_res, epochs=10, batch_size=32, verbose=0)\n",
    "Y_pred_proba_cnn = cnn_model.predict(X_test_cnn).flatten()\n",
    "Y_pred_cnn = (Y_pred_proba_cnn > 0.5).astype(int)\n",
    "calculate_metrics(Y_test, Y_pred_cnn, 'CNN')\n",
    "fpr_cnn, tpr_cnn, _ = roc_curve(Y_test, Y_pred_proba_cnn)\n",
    "roc_auc_cnn = auc(fpr_cnn, tpr_cnn)\n",
    "plot_roc_curve(fpr_cnn, tpr_cnn, roc_auc_cnn, 'CNN')\n",
    "\n",
    "# 7. Deep Neural Network (abbreviation: DNN)\n",
    "dnn_model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_res.shape[1],), kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.5),\n",
    "    Dense(16, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "dnn_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "dnn_model.fit(X_train_res, Y_train_res, epochs=10, batch_size=32, verbose=0)\n",
    "Y_pred_proba_dnn = dnn_model.predict(X_test).flatten()\n",
    "Y_pred_dnn = (Y_pred_proba_dnn > 0.5).astype(int)\n",
    "calculate_metrics(Y_test, Y_pred_dnn, 'DNN')\n",
    "fpr_dnn, tpr_dnn, _ = roc_curve(Y_test, Y_pred_proba_dnn)\n",
    "roc_auc_dnn = auc(fpr_dnn, tpr_dnn)\n",
    "plot_roc_curve(fpr_dnn, tpr_dnn, roc_auc_dnn, 'DNN')\n",
    "\n",
    "# Plot the ROC curves\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Print metrics for each model\n",
    "for model, metric in metrics.items():\n",
    "    print(f\"{model} Metrics:\")\n",
    "    for key, value in metric.items():\n",
    "        print(f\"  {key}: {value:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
