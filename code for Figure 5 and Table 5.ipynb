{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee615db-0dd8-4e3a-a74f-10e9903b14fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, MaxPooling1D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_excel('hechuan ube pre 3.xlsx')\n",
    "\n",
    "# Split the data into features (X) and target variable (Y)\n",
    "X = data.drop(['ID', 'los', 'elos'], axis=1)\n",
    "Y = data['elos']\n",
    "\n",
    "# Convert Y to binary classification (if necessary)\n",
    "Y = (Y > Y.median()).astype(int)\n",
    "\n",
    "# 数据增强（SMOTE）\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, Y_res = smote.fit_resample(X, Y)\n",
    "\n",
    "# 特征标准化\n",
    "scaler = StandardScaler()\n",
    "X_res_scaled = scaler.fit_transform(X_res)\n",
    "\n",
    "# Define models with adjusted parameters\n",
    "models = {\n",
    "    'XGB': XGBClassifier(\n",
    "        random_state=42,\n",
    "        n_estimators=10,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.05,\n",
    "        reg_alpha=1.0,\n",
    "        reg_lambda=1.0,\n",
    "        subsample=0.5,\n",
    "        colsample_bytree=0.5\n",
    "    ),\n",
    "    'GBM': GradientBoostingClassifier(\n",
    "        random_state=42,\n",
    "        n_estimators=5,\n",
    "        learning_rate=0.001,\n",
    "        max_depth=1\n",
    "    ),\n",
    "    'RF': RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        n_estimators=5,\n",
    "        max_depth=1,\n",
    "        max_features='sqrt'\n",
    "    ),\n",
    "    'LR': LogisticRegression(\n",
    "        random_state=42,\n",
    "        penalty='l2',\n",
    "        C=0.00001\n",
    "    ),\n",
    "    'Lasso LR': LogisticRegression(\n",
    "        penalty='l1',\n",
    "        solver='liblinear',\n",
    "        C=0.1,\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# Define CNN and DNN models\n",
    "def create_cnn_model():\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=16, kernel_size=3, activation='relu', input_shape=(X_res.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(16, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_dnn_model():\n",
    "    model = Sequential([\n",
    "        Dense(16, activation='relu', input_shape=(X_res.shape[1],), kernel_regularizer=l2(0.01)),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "models['CNN'] = create_cnn_model()\n",
    "models['DNN'] = create_dnn_model()\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "metrics = {\n",
    "    model_name: {\n",
    "        'Accuracy': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1 Score': [],\n",
    "        'AUC': []\n",
    "    } for model_name in models.keys()\n",
    "}\n",
    "\n",
    "for train_index, test_index in skf.split(X_res_scaled, Y_res):\n",
    "    X_train_fold, X_test_fold = X_res_scaled[train_index], X_res_scaled[test_index]\n",
    "    Y_train_fold, Y_test_fold = Y_res[train_index], Y_res[test_index]\n",
    "\n",
    "    # Train models\n",
    "    for model_name, model in models.items():\n",
    "        if model_name in ['CNN', 'DNN']:\n",
    "            X_train_cnn = X_train_fold.reshape((X_train_fold.shape[0], X_train_fold.shape[1], 1))\n",
    "            X_test_cnn = X_test_fold.reshape((X_test_fold.shape[0], X_test_fold.shape[1], 1))\n",
    "            model.fit(X_train_cnn, Y_train_fold, epochs=5, batch_size=16, verbose=0)\n",
    "            Y_pred = model.predict(X_test_cnn).flatten()\n",
    "        else:\n",
    "            model.fit(X_train_fold, Y_train_fold)\n",
    "            Y_pred = model.predict_proba(X_test_fold)[:, 1]\n",
    "\n",
    "        # Convert probabilities to binary predictions for CNN and DNN\n",
    "        if model_name in ['CNN', 'DNN']:\n",
    "            Y_pred_binary = (Y_pred > 0.5).astype(int)\n",
    "        else:\n",
    "            Y_pred_binary = model.predict(X_test_fold)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(Y_test_fold, Y_pred_binary)\n",
    "        precision = precision_score(Y_test_fold, Y_pred_binary)\n",
    "        recall = recall_score(Y_test_fold, Y_pred_binary)\n",
    "        f1 = f1_score(Y_test_fold, Y_pred_binary)\n",
    "        fpr, tpr, _ = roc_curve(Y_test_fold, Y_pred)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        # Store metrics\n",
    "        metrics[model_name]['Accuracy'].append(accuracy)\n",
    "        metrics[model_name]['Precision'].append(precision)\n",
    "        metrics[model_name]['Recall'].append(recall)\n",
    "        metrics[model_name]['F1 Score'].append(f1)\n",
    "        metrics[model_name]['AUC'].append(roc_auc)\n",
    "\n",
    "# Calculate average metrics for each model\n",
    "average_metrics = {\n",
    "    model_name: {\n",
    "        metric: np.mean(values) for metric, values in model_metrics.items()\n",
    "    } for model_name, model_metrics in metrics.items()\n",
    "}\n",
    "\n",
    "# Print average metrics for each model\n",
    "for model_name, model_metrics in average_metrics.items():\n",
    "    print(f\"{model_name} Metrics:\")\n",
    "    for metric, value in model_metrics.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "# ...\n",
    "\n",
    "# Plot ROC curves for each model\n",
    "plt.figure(figsize=(10, 8))\n",
    "for model_name, model in models.items():\n",
    "    if model_name in ['CNN', 'DNN']:\n",
    "        X_train_cnn = X_res_scaled.reshape((X_res_scaled.shape[0], X_res_scaled.shape[1], 1))\n",
    "        X_test_cnn = X_res_scaled.reshape((X_res_scaled.shape[0], X_res_scaled.shape[1], 1))\n",
    "        model.fit(X_train_cnn, Y_res, epochs=5, batch_size=16, verbose=0)\n",
    "        Y_pred = model.predict(X_test_cnn).flatten()\n",
    "    else:\n",
    "        model.fit(X_res_scaled, Y_res)\n",
    "        Y_pred = model.predict_proba(X_res_scaled)[:, 1]\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(Y_res, Y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Store the last iteration's AUC for comparison\n",
    "    if model_name not in metrics:\n",
    "        metrics[model_name] = {'AUC': []}\n",
    "    metrics[model_name]['AUC'].append(roc_auc)\n",
    "\n",
    "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Print the last iteration's AUC for comparison\n",
    "for model_name, model_metrics in metrics.items():\n",
    "    print(f\"{model_name} Last Iteration AUC: {model_metrics['AUC'][-1]:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
